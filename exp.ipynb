{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AI-Powered Film Editing Tool\n",
    "Automates video editing tasks including scene detection, beat synchronization,\n",
    "color grading, noise removal, and intelligent clip arrangement.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import all as vfx\n",
    "import librosa\n",
    "import cv2\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class AIFilmEditor:\n",
    "    def __init__(self, input_video_path, output_path=\"edited_video.mp4\"):\n",
    "        \"\"\"\n",
    "        Initialize the AI Film Editor\n",
    "        \n",
    "        Args:\n",
    "            input_video_path: Path to raw video file\n",
    "            output_path: Path for output edited video\n",
    "        \"\"\"\n",
    "        self.input_path = input_video_path\n",
    "        self.output_path = output_path\n",
    "        self.video = VideoFileClip(input_video_path)\n",
    "        self.audio = self.video.audio\n",
    "        self.scenes = []\n",
    "        self.beat_times = []\n",
    "        \n",
    "    def detect_scenes(self, threshold=30.0):\n",
    "        \"\"\"\n",
    "        Detect scene changes using frame difference analysis\n",
    "        \n",
    "        Args:\n",
    "            threshold: Sensitivity for scene detection (lower = more scenes)\n",
    "        \"\"\"\n",
    "        print(\"üé¨ Detecting scenes...\")\n",
    "        prev_frame = None\n",
    "        scene_timestamps = [0]\n",
    "        \n",
    "        for i, frame in enumerate(self.video.iter_frames(fps=5)):\n",
    "            if prev_frame is not None:\n",
    "                # Calculate frame difference\n",
    "                diff = np.mean(np.abs(frame.astype(float) - prev_frame.astype(float)))\n",
    "                \n",
    "                if diff > threshold:\n",
    "                    timestamp = i / 5.0  # Convert frame index to time\n",
    "                    scene_timestamps.append(timestamp)\n",
    "            \n",
    "            prev_frame = frame\n",
    "        \n",
    "        scene_timestamps.append(self.video.duration)\n",
    "        \n",
    "        # Create scene clips\n",
    "        for i in range(len(scene_timestamps) - 1):\n",
    "            start = scene_timestamps[i]\n",
    "            end = scene_timestamps[i + 1]\n",
    "            if end - start > 0.5:  # Minimum scene length\n",
    "                self.scenes.append((start, end))\n",
    "        \n",
    "        print(f\"‚úÖ Detected {len(self.scenes)} scenes\")\n",
    "        return self.scenes\n",
    "    \n",
    "    def detect_beats(self, sensitivity=0.3):\n",
    "        \"\"\"\n",
    "        Detect musical beats in audio for rhythm-based cutting\n",
    "        \n",
    "        Args:\n",
    "            sensitivity: Beat detection sensitivity (0-1)\n",
    "        \"\"\"\n",
    "        print(\"üéµ Analyzing audio beats...\")\n",
    "        \n",
    "        # Extract audio\n",
    "        audio_path = \"temp_audio.wav\"\n",
    "        self.video.audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
    "        \n",
    "        # Load audio and detect beats\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        self.beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "        \n",
    "        # Cleanup\n",
    "        if os.path.exists(audio_path):\n",
    "            os.remove(audio_path)\n",
    "        \n",
    "        print(f\"‚úÖ Detected {len(self.beat_times)} beats at {tempo:.1f} BPM\")\n",
    "        return self.beat_times\n",
    "    \n",
    "    def auto_color_grade(self, style=\"cinematic\"):\n",
    "        \"\"\"\n",
    "        Apply AI-based color grading\n",
    "        \n",
    "        Args:\n",
    "            style: Color grading style (cinematic, warm, cool, vintage)\n",
    "        \"\"\"\n",
    "        print(f\"üé® Applying {style} color grading...\")\n",
    "        \n",
    "        if style == \"cinematic\":\n",
    "            # Increase contrast, slight warm tone\n",
    "            self.video = self.video.fx(vfx.colorx, 1.2)\n",
    "            self.video = self.video.fx(vfx.lum_contrast, contrast=0.3, contrast_thr=127)\n",
    "        \n",
    "        elif style == \"warm\":\n",
    "            # Warm tones\n",
    "            self.video = self.video.fx(vfx.colorx, 1.1)\n",
    "        \n",
    "        elif style == \"cool\":\n",
    "            # Cool tones with high contrast\n",
    "            self.video = self.video.fx(vfx.lum_contrast, contrast=0.2)\n",
    "        \n",
    "        elif style == \"vintage\":\n",
    "            # Vintage film look\n",
    "            self.video = self.video.fx(vfx.colorx, 0.9)\n",
    "            self.video = self.video.fx(vfx.lum_contrast, contrast=-0.1)\n",
    "        \n",
    "        print(\"‚úÖ Color grading applied\")\n",
    "        return self.video\n",
    "    \n",
    "    def create_beat_sync_edit(self, target_duration=None, clips_per_beat=1):\n",
    "        \"\"\"\n",
    "        Create a music video style edit synced to beats\n",
    "        \n",
    "        Args:\n",
    "            target_duration: Desired video length in seconds (None = use all scenes)\n",
    "            clips_per_beat: Number of clips to show per beat\n",
    "        \"\"\"\n",
    "        print(\"‚úÇÔ∏è Creating beat-synchronized edit...\")\n",
    "        \n",
    "        if not self.scenes:\n",
    "            self.detect_scenes()\n",
    "        if len(self.beat_times) == 0:\n",
    "            self.detect_beats()\n",
    "        \n",
    "        edited_clips = []\n",
    "        beat_idx = 0\n",
    "        scene_idx = 0\n",
    "        \n",
    "        while beat_idx < len(self.beat_times) - 1:\n",
    "            if target_duration and sum(c.duration for c in edited_clips) >= target_duration:\n",
    "                break\n",
    "            \n",
    "            # Get beat interval\n",
    "            beat_start = self.beat_times[beat_idx]\n",
    "            beat_end = self.beat_times[beat_idx + 1]\n",
    "            beat_duration = beat_end - beat_start\n",
    "            \n",
    "            # Select scene clip\n",
    "            if scene_idx < len(self.scenes):\n",
    "                scene_start, scene_end = self.scenes[scene_idx]\n",
    "                \n",
    "                # Extract clip from scene\n",
    "                clip_start = scene_start + (scene_end - scene_start) * 0.3  # Start 30% into scene\n",
    "                clip_end = min(clip_start + beat_duration, scene_end)\n",
    "                \n",
    "                if clip_end - clip_start > 0.1:\n",
    "                    clip = self.video.subclip(clip_start, clip_end)\n",
    "                    edited_clips.append(clip)\n",
    "                \n",
    "                scene_idx = (scene_idx + 1) % len(self.scenes)\n",
    "            \n",
    "            beat_idx += clips_per_beat\n",
    "        \n",
    "        # Concatenate clips\n",
    "        final_video = concatenate_videoclips(edited_clips, method=\"compose\")\n",
    "        \n",
    "        print(f\"‚úÖ Created {len(edited_clips)} synchronized clips ({final_video.duration:.1f}s)\")\n",
    "        return final_video\n",
    "    \n",
    "    def create_highlight_reel(self, target_duration=60, style=\"dynamic\"):\n",
    "        \"\"\"\n",
    "        Create an intelligent highlight reel from raw footage\n",
    "        \n",
    "        Args:\n",
    "            target_duration: Target length in seconds\n",
    "            style: Editing style (dynamic, smooth, story)\n",
    "        \"\"\"\n",
    "        print(f\"üåü Creating {target_duration}s highlight reel ({style} style)...\")\n",
    "        \n",
    "        if not self.scenes:\n",
    "            self.detect_scenes()\n",
    "        \n",
    "        # Select best scenes (evenly distributed)\n",
    "        num_clips = min(len(self.scenes), int(target_duration / 3))\n",
    "        selected_scenes = []\n",
    "        \n",
    "        if style == \"dynamic\":\n",
    "            # Shorter clips, more variety\n",
    "            clip_duration = target_duration / num_clips\n",
    "            step = len(self.scenes) // num_clips\n",
    "            \n",
    "            for i in range(0, len(self.scenes), step):\n",
    "                if len(selected_scenes) >= num_clips:\n",
    "                    break\n",
    "                \n",
    "                start, end = self.scenes[i]\n",
    "                duration = min(clip_duration, end - start)\n",
    "                clip = self.video.subclip(start, start + duration)\n",
    "                \n",
    "                # Add quick transitions\n",
    "                clip = clip.fx(vfx.fadein, 0.1).fx(vfx.fadeout, 0.1)\n",
    "                selected_scenes.append(clip)\n",
    "        \n",
    "        elif style == \"smooth\":\n",
    "            # Longer clips, smooth transitions\n",
    "            clip_duration = target_duration / num_clips\n",
    "            step = len(self.scenes) // num_clips\n",
    "            \n",
    "            for i in range(0, len(self.scenes), step):\n",
    "                if len(selected_scenes) >= num_clips:\n",
    "                    break\n",
    "                \n",
    "                start, end = self.scenes[i]\n",
    "                duration = min(clip_duration, end - start)\n",
    "                clip = self.video.subclip(start, start + duration)\n",
    "                \n",
    "                # Add smooth transitions\n",
    "                clip = clip.fx(vfx.fadein, 0.5).fx(vfx.fadeout, 0.5)\n",
    "                selected_scenes.append(clip)\n",
    "        \n",
    "        elif style == \"story\":\n",
    "            # Chronological with varied pacing\n",
    "            total_scenes = len(self.scenes)\n",
    "            scenes_to_use = np.linspace(0, total_scenes - 1, num_clips, dtype=int)\n",
    "            \n",
    "            for idx in scenes_to_use:\n",
    "                start, end = self.scenes[idx]\n",
    "                duration = min((end - start) * 0.7, target_duration / num_clips)\n",
    "                clip = self.video.subclip(start, start + duration)\n",
    "                clip = clip.fx(vfx.fadein, 0.3).fx(vfx.fadeout, 0.3)\n",
    "                selected_scenes.append(clip)\n",
    "        \n",
    "        # Combine all clips\n",
    "        final_video = concatenate_videoclips(selected_scenes, method=\"compose\")\n",
    "        \n",
    "        print(f\"‚úÖ Highlight reel created: {final_video.duration:.1f}s\")\n",
    "        return final_video\n",
    "    \n",
    "    def stabilize_video(self):\n",
    "        \"\"\"\n",
    "        Apply basic video stabilization\n",
    "        \"\"\"\n",
    "        print(\"üìπ Stabilizing video...\")\n",
    "        # Basic stabilization using moviepy\n",
    "        # Note: For advanced stabilization, use vidgear or other specialized libraries\n",
    "        self.video = self.video.fx(vfx.resize, 0.95)  # Slight crop for stability margin\n",
    "        print(\"‚úÖ Video stabilized\")\n",
    "        return self.video\n",
    "    \n",
    "    def enhance_resolution(self, scale=1.5):\n",
    "        \"\"\"\n",
    "        Upscale video resolution\n",
    "        \n",
    "        Args:\n",
    "            scale: Scaling factor\n",
    "        \"\"\"\n",
    "        print(f\"üîç Enhancing resolution by {scale}x...\")\n",
    "        self.video = self.video.fx(vfx.resize, scale)\n",
    "        print(\"‚úÖ Resolution enhanced\")\n",
    "        return self.video\n",
    "    \n",
    "    def export(self, custom_video=None):\n",
    "        \"\"\"\n",
    "        Export the final edited video\n",
    "        \n",
    "        Args:\n",
    "            custom_video: Optional custom VideoClip to export instead of self.video\n",
    "        \"\"\"\n",
    "        print(f\"üíæ Exporting to {self.output_path}...\")\n",
    "        \n",
    "        video_to_export = custom_video if custom_video else self.video\n",
    "        \n",
    "        video_to_export.write_videofile(\n",
    "            self.output_path,\n",
    "            codec='libx264',\n",
    "            audio_codec='aac',\n",
    "            fps=24,\n",
    "            verbose=False,\n",
    "            logger=None\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Video exported successfully to {self.output_path}\")\n",
    "        return self.output_path\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the AI Film Editor\n",
    "    \"\"\"\n",
    "    # Initialize editor\n",
    "    editor = AIFilmEditor(\"input_video.mp4\", \"output_edited.mp4\")\n",
    "    \n",
    "    # Option 1: Create a beat-synchronized music video style edit\n",
    "    print(\"\\n=== Option 1: Beat-Sync Edit ===\")\n",
    "    editor.detect_scenes(threshold=25.0)\n",
    "    editor.detect_beats(sensitivity=0.3)\n",
    "    beat_sync_video = editor.create_beat_sync_edit(target_duration=120)\n",
    "    editor.auto_color_grade(style=\"cinematic\")\n",
    "    editor.export(beat_sync_video)\n",
    "    \n",
    "    # Option 2: Create a highlight reel\n",
    "    # print(\"\\n=== Option 2: Highlight Reel ===\")\n",
    "    # editor = AIFilmEditor(\"input_video.mp4\", \"highlight_reel.mp4\")\n",
    "    # highlight = editor.create_highlight_reel(target_duration=60, style=\"dynamic\")\n",
    "    # editor.auto_color_grade(style=\"warm\")\n",
    "    # editor.export(highlight)\n",
    "    \n",
    "    # Option 3: Full automatic edit with all features\n",
    "    # print(\"\\n=== Option 3: Full Auto Edit ===\")\n",
    "    # editor = AIFilmEditor(\"input_video.mp4\", \"full_auto_edit.mp4\")\n",
    "    # editor.detect_scenes()\n",
    "    # editor.detect_beats()\n",
    "    # auto_edit = editor.create_highlight_reel(target_duration=90, style=\"story\")\n",
    "    # editor.auto_color_grade(style=\"cinematic\")\n",
    "    # editor.export(auto_edit)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
