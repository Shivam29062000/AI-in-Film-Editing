{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7dc766",
   "metadata": {},
   "source": [
    "***\n",
    "AI-Powered Film Editing Tool\n",
    "Automates video editing tasks including scene detection, beat synchronization,\n",
    "color grading, noise removal, and intelligent clip arrangement.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4e16a",
   "metadata": {},
   "source": [
    "Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import all as vfx\n",
    "import librosa\n",
    "import cv2\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df6508",
   "metadata": {},
   "source": [
    "***\n",
    "Creating Class for processing and editing video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeee94c",
   "metadata": {},
   "source": [
    "- detect_scenes: Detect scene changes using frame difference analysis\n",
    "- detect_beats: Detect musical beats in audio for rhythm-based cutting\n",
    "- auto_color_grade: Apply AI-based color grading\n",
    "- create_beat_sync_edit: Create a music video style edit synced to beats\n",
    "- stabilize_video: Apply basic video stabilization\n",
    "- enhance_resolution: Upscale video resolution\n",
    "- export: Export the final video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AIFilmEditor:\n",
    "    def __init__(self, input_video_path, output_path=\"edited_video.mp4\"):\n",
    "        \"\"\"\n",
    "        Initialize the AI Film Editor\n",
    "        \n",
    "        Args:\n",
    "            input_video_path: Path to raw video file\n",
    "            output_path: Path for output edited video\n",
    "        \"\"\"\n",
    "        self.input_path = input_video_path\n",
    "        self.output_path = output_path\n",
    "        self.video = VideoFileClip(input_video_path)\n",
    "        self.audio = self.video.audio\n",
    "        self.scenes = []\n",
    "        self.beat_times = []\n",
    "        \n",
    "    def detect_scenes(self, threshold=30.0):\n",
    "        \"\"\"\n",
    "        Detect scene changes using frame difference analysis\n",
    "        \n",
    "        Args:\n",
    "            threshold: Sensitivity for scene detection (lower = more scenes)\n",
    "        \"\"\"\n",
    "        print(\"üé¨ Detecting scenes...\")\n",
    "        prev_frame = None\n",
    "        scene_timestamps = [0]\n",
    "        \n",
    "        for i, frame in enumerate(self.video.iter_frames(fps=5)):\n",
    "            if prev_frame is not None:\n",
    "                # Calculate frame difference\n",
    "                diff = np.mean(np.abs(frame.astype(float) - prev_frame.astype(float)))\n",
    "                \n",
    "                if diff > threshold:\n",
    "                    timestamp = i / 5.0  # Convert frame index to time\n",
    "                    scene_timestamps.append(timestamp)\n",
    "            \n",
    "            prev_frame = frame\n",
    "        \n",
    "        scene_timestamps.append(self.video.duration)\n",
    "        \n",
    "        # Create scene clips\n",
    "        for i in range(len(scene_timestamps) - 1):\n",
    "            start = scene_timestamps[i]\n",
    "            end = scene_timestamps[i + 1]\n",
    "            if end - start > 0.5:  # Minimum scene length\n",
    "                self.scenes.append((start, end))\n",
    "        \n",
    "        print(f\"‚úÖ Detected {len(self.scenes)} scenes\")\n",
    "        return self.scenes\n",
    "    \n",
    "    def detect_beats(self, sensitivity=0.3):\n",
    "        \"\"\"\n",
    "        Detect musical beats in audio for rhythm-based cutting\n",
    "        \n",
    "        Args:\n",
    "            sensitivity: Beat detection sensitivity (0-1)\n",
    "        \"\"\"\n",
    "        print(\"üéµ Analyzing audio beats...\")\n",
    "        \n",
    "        # Extract audio\n",
    "        audio_path = \"temp_audio.wav\"\n",
    "        self.video.audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
    "        \n",
    "        # Load audio and detect beats\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        self.beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "        \n",
    "        # Cleanup\n",
    "        if os.path.exists(audio_path):\n",
    "            os.remove(audio_path)\n",
    "        \n",
    "        print(f\"‚úÖ Detected {len(self.beat_times)} beats at {tempo:.1f} BPM\")\n",
    "        return self.beat_times\n",
    "    \n",
    "    def auto_color_grade(self, style=\"cinematic\"):\n",
    "        \"\"\"\n",
    "        Apply AI-based color grading\n",
    "        \n",
    "        Args:\n",
    "            style: Color grading style (cinematic, warm, cool, vintage)\n",
    "        \"\"\"\n",
    "        print(f\"üé® Applying {style} color grading...\")\n",
    "        \n",
    "        if style == \"cinematic\":\n",
    "            # Increase contrast, slight warm tone\n",
    "            self.video = self.video.fx(vfx.colorx, 1.2)\n",
    "            self.video = self.video.fx(vfx.lum_contrast, contrast=0.3, contrast_thr=127)\n",
    "        \n",
    "        elif style == \"warm\":\n",
    "            # Warm tones\n",
    "            self.video = self.video.fx(vfx.colorx, 1.1)\n",
    "        \n",
    "        elif style == \"cool\":\n",
    "            # Cool tones with high contrast\n",
    "            self.video = self.video.fx(vfx.lum_contrast, contrast=0.2)\n",
    "        \n",
    "        elif style == \"vintage\":\n",
    "            # Vintage film look\n",
    "            self.video = self.video.fx(vfx.colorx, 0.9)\n",
    "            self.video = self.video.fx(vfx.lum_contrast, contrast=-0.1)\n",
    "        \n",
    "        print(\"‚úÖ Color grading applied\")\n",
    "        return self.video\n",
    "    \n",
    "    def create_beat_sync_edit(self, target_duration=None, clips_per_beat=1):\n",
    "        \"\"\"\n",
    "        Create a music video style edit synced to beats\n",
    "        \n",
    "        Args:\n",
    "            target_duration: Desired video length in seconds (None = use all scenes)\n",
    "            clips_per_beat: Number of clips to show per beat\n",
    "        \"\"\"\n",
    "        print(\"‚úÇÔ∏è Creating beat-synchronized edit...\")\n",
    "        \n",
    "        if not self.scenes:\n",
    "            self.detect_scenes()\n",
    "        if len(self.beat_times) == 0:\n",
    "            self.detect_beats()\n",
    "        \n",
    "        edited_clips = []\n",
    "        beat_idx = 0\n",
    "        scene_idx = 0\n",
    "        \n",
    "        while beat_idx < len(self.beat_times) - 1:\n",
    "            if target_duration and sum(c.duration for c in edited_clips) >= target_duration:\n",
    "                break\n",
    "            \n",
    "            # Get beat interval\n",
    "            beat_start = self.beat_times[beat_idx]\n",
    "            beat_end = self.beat_times[beat_idx + 1]\n",
    "            beat_duration = beat_end - beat_start\n",
    "            \n",
    "            # Select scene clip\n",
    "            if scene_idx < len(self.scenes):\n",
    "                scene_start, scene_end = self.scenes[scene_idx]\n",
    "                \n",
    "                # Extract clip from scene\n",
    "                clip_start = scene_start + (scene_end - scene_start) * 0.3  # Start 30% into scene\n",
    "                clip_end = min(clip_start + beat_duration, scene_end)\n",
    "                \n",
    "                if clip_end - clip_start > 0.1:\n",
    "                    clip = self.video.subclip(clip_start, clip_end)\n",
    "                    edited_clips.append(clip)\n",
    "                \n",
    "                scene_idx = (scene_idx + 1) % len(self.scenes)\n",
    "            \n",
    "            beat_idx += clips_per_beat\n",
    "        \n",
    "        # Concatenate clips\n",
    "        final_video = concatenate_videoclips(edited_clips, method=\"compose\")\n",
    "        \n",
    "        print(f\"‚úÖ Created {len(edited_clips)} synchronized clips ({final_video.duration:.1f}s)\")\n",
    "        return final_video\n",
    "    \n",
    "    \n",
    "    def stabilize_video(self):\n",
    "        \"\"\"\n",
    "        Apply basic video stabilization\n",
    "        \"\"\"\n",
    "        print(\"üìπ Stabilizing video...\")\n",
    "        # Basic stabilization using moviepy\n",
    "        # Note: For advanced stabilization, use vidgear or other specialized libraries\n",
    "        self.video = self.video.fx(vfx.resize, 0.95)  # Slight crop for stability margin\n",
    "        print(\"‚úÖ Video stabilized\")\n",
    "        return self.video\n",
    "    \n",
    "    def enhance_resolution(self, scale=1.5):\n",
    "        \"\"\"\n",
    "        Upscale video resolution\n",
    "        \n",
    "        Args:\n",
    "            scale: Scaling factor\n",
    "        \"\"\"\n",
    "        print(f\"üîç Enhancing resolution by {scale}x...\")\n",
    "        self.video = self.video.fx(vfx.resize, scale)\n",
    "        print(\"‚úÖ Resolution enhanced\")\n",
    "        return self.video\n",
    "    \n",
    "    def export(self, custom_video=None):\n",
    "        \"\"\"\n",
    "        Export the final edited video\n",
    "        \n",
    "        Args:\n",
    "            custom_video: Optional custom VideoClip to export instead of self.video\n",
    "        \"\"\"\n",
    "        print(f\"üíæ Exporting to {self.output_path}...\")\n",
    "        \n",
    "        video_to_export = custom_video if custom_video else self.video\n",
    "        \n",
    "        video_to_export.write_videofile(\n",
    "            self.output_path,\n",
    "            codec='libx264',\n",
    "            audio_codec='aac',\n",
    "            fps=24,\n",
    "            verbose=False,\n",
    "            logger=None\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Video exported successfully to {self.output_path}\")\n",
    "        return self.output_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f932037",
   "metadata": {},
   "source": [
    "**Final Function which will use the AIFilmEditor to create and export the final edited video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fda34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the AI Film Editor\n",
    "    \"\"\"\n",
    "    # Initialize editor\n",
    "    editor = AIFilmEditor(\"input_video.mp4\", \"output_edited.mp4\")\n",
    "    \n",
    "    # Create a beat-synchronized music video style edit\n",
    "    print(\"\\n=== Option 1: Beat-Sync Edit ===\")\n",
    "    editor.detect_scenes(threshold=25.0)\n",
    "    editor.detect_beats(sensitivity=0.3)\n",
    "    beat_sync_video = editor.create_beat_sync_edit(target_duration=120)\n",
    "    editor.auto_color_grade(style=\"cinematic\")\n",
    "    editor.export(beat_sync_video)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
